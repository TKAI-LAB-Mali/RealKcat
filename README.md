# RealKcat: Robust Prediction of Enzyme Variant Kinetics

## Overview
Welcome to the RealKcat repository! This project provides a reproducible pipeline to predict enzyme kinetics parameters, specifically `kcat` and `km`, using curated datasets. The repository includes tools and scripts for training and inference of both `kcat` and `km` models, along with utilities for data processing, model training, and standardized prediction.

---
## **Quick Inference with Pretrained Model:**  
For a hands-on demonstration and interactive inference, use our [`RealKcat_Inference_Interface.ipynb`](https://colab.research.google.com/drive/1z8cPg2J-EF01rd0yl7fgGlvWDohOj5m0?usp=sharing) notebook. Open it directly in Google Colab:

[![Open in Colab](https://colab.research.google.com/assets/colab-btn.svg)](https://colab.research.google.com/drive/1z8cPg2J-EF01rd0yl7fgGlvWDohOj5m0?usp=sharing)

This notebook allows you to perform inference on `kcat` and `km` predictions without needing to install or configure anything locally. Simply connect to a Colab runtime, follow the provided instructions, and start exploring the RealKcat models interactively.

If you only want to make predictions with the pretrained model locally without retraining, you can use the **RealKcat_Inference.ipynb** notebook. This notebook offers an easy, interactive way to explore and make predictions for `kcat` and `km` values. Just provide your enzyme sequence and substrate Isomeric SMILES, and the notebook will guide you through the prediction process.

---

## Retraining the Models

If youâ€™re interested in retraining the models and reproducing the results from scratch, please follow the steps below to download and set up the required datasets.

## ðŸ“‚ Download and Setup the Datasets

Follow these steps to download and correctly set up the datasets in the repository's `data` folder:

1. **Download the Dataset**:
   - Visit [Chowdhury Lab Downloads](https://chowdhurylab.github.io/downloads.html).
   - Locate **KinHub-27k (Manually-curated Enzyme Parameter Database; verified from 2158 papers)** and download the dataset file (e.g., `KinHub-27k.zip`).

2. **Move the Downloaded File**:
   - Move `KinHub-27k.zip` to the `data` folder in the root directory of this repository.

3. **Extract the Files into the `data` Directory**:
   - Open a terminal or command prompt, navigate to the `data` directory, and unzip the dataset:
     ```bash
     cd path/to/RealKcat/data
     ```
     - **On Linux/macOS**:
       ```bash
       unzip KinHub-27k.zip
       ```
     - **On Windows** (using Command Prompt or Git Bash):
       ```bash
       tar -xf KinHub-27k.zip
       ```
     - Alternatively, on Windows, you can right-click `KinHub-27k.zip` and choose "Extract All..." to unzip directly into the `data` folder.

4. **Verify the Extracted Files**:
   - After extraction, your `data` folder should have the following structure:

     ```
     data/
     â”œâ”€â”€ data_split/
     â”œâ”€â”€ PafA_data/
     â”œâ”€â”€ Save_kinetic_bin_range.pkl
     â”œâ”€â”€ WT_MD_database_v1.xlsx
     â”œâ”€â”€ WT_MD_dataset.pt
     â”œâ”€â”€ WT_MD_dataset_wNeg.pt
     ```

5. **Proceed with Training or Inference**:
   - With the data set up, you can now use the provided scripts to perform training or inference.

## Repository Structure

The `RealKcat` directory should be organized as follows:

```plaintext
RealKcat/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ PafA_data/
â”‚   â”‚   â”œâ”€â”€ PafA_1_test_dataset_2.pt
â”‚   â”‚   â”œâ”€â”€ PafA_1_test_positions_2.pt
â”‚   â”‚   â””â”€â”€ PafA_1_test_kcat_km_2.pt
â”‚   â”œâ”€â”€ data_split/
â”‚   â”œâ”€â”€ Save_kinetic_bin_range.pkl
â”‚   â”œâ”€â”€ WT_MD_database_v1.xlsx
â”‚   â”œâ”€â”€ WT_MD_dataset.pt
â”‚   â””â”€â”€ WT_MD_dataset_wNeg.pt
â”œâ”€â”€ outputs/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ test_ood_kcat_predict.py
â”‚   â”œâ”€â”€ test_ood_km_predict.py
â”‚   â”œâ”€â”€ test_PafA_kcat_predict.py
â”‚   â”œâ”€â”€ test_PafA_km_predict.py
â”‚   â”œâ”€â”€ train_kcat_model.py
â”‚   â””â”€â”€ train_km_model.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_processing.py
â”‚   â”œâ”€â”€ evaluation.py
â”‚   â”œâ”€â”€ model_training.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ RealKcat_Inference.ipynb
```

### Key Directories and Files

- **data/**: Contains all datasets, including training and test data, as well as supplementary files (e.g., bin range statistics for kinetic parameters).
  - `PafA_data/`: Datasets specifically for testing on the PafA enzyme.
  - `WT_MD_*`: Datasets for wild-type (WT) and mutant datasets.
- **outputs/**: Directory for saving model outputs, trained models, and prediction results.
- **scripts/**: Contains scripts for training and testing models.
  - `train_kcat_model.py` and `train_km_model.py`: Scripts for training models to predict `kcat` and `km`, respectively.
  - `test_*`: Scripts to run inference on test datasets for both `kcat` and `km`.
- **src/**: Contains utility scripts for data processing, model training, evaluation, and general utilities.
  - `data_processing.py`: Functions for loading and preparing datasets, standardizing data, and handling tensor data.
  - `model_training.py`: Functions for initializing and training XGBoost models with hyperparameters.
  - `evaluation.py`: Functions to evaluate model performance.
  - `utils.py`: Utility functions for device selection, setting seeds, etc.
- **RealKcat_Inference.ipynb**: Jupyter notebook for interactive inference.
- **README.md**: This file, providing documentation for the repository.

## Installation

### Prerequisites

- Python 3.8 or higher (code is compatible with Python 3.12)
- Required libraries are listed in `requirements.txt`.

### Install Dependencies

To set up your environment, clone the repository and install the dependencies:

```bash
git clone https://github.com/TKAI-LAB-Mali/RealKcat
cd RealKcat
pip install -r requirements.txt
```

## Usage

### 1. Training Models

To train models for `kcat` and `km`:

```bash
# Train kcat model
python scripts/train_kcat_model.py

# Train km model
python scripts/train_km_model.py
```

These scripts load datasets, standardize them, and train models with specified hyperparameters.

### 2. Running Inference

Run inference on test datasets using the trained models. Each `test_*_predict.py` script loads a model and dataset, applies standardization, and makes predictions.

#### Out-of-Distribution (OOD) Inference

Evaluate the model's performance on an out-of-distribution (OOD) dataset to test its robustness.

```bash
# Predict kcat on OOD dataset
python scripts/test_ood_kcat_predict.py

# Predict km on OOD dataset
python scripts/test_ood_km_predict.py
```

#### PafA Enzyme Inference

Use the PafA dataset for detailed testing on a specific enzyme.

```bash
# Predict kcat on PafA dataset
python scripts/test_PafA_kcat_predict.py

# Predict km on PafA dataset
python scripts/test_PafA_km_predict.py
```

### 3. Results and Visualization

Model outputs, trained models, and prediction results are saved as figures in the `outputs/` directory.

## License

This project is licensed under the MIT License. See the `LICENSE` file for details.

## Contributing

Contributions are welcome! Please open an issue or submit a pull request for any improvements or bug fixes. 
